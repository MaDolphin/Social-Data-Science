{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social Data Science WS19/20\n",
    "\n",
    "# Home Assignment 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your solution via Moodle until 23.59pm on Wednesday, November 27th. Late submissions are accepted for 12 hours following the deadline, with 1/3 of the total possible points deducted from the score.\n",
    "\n",
    "Submit your solutions in teams of up 2-3 members. **Single student submissions will not be graded anymore.**\n",
    "Please denote all members of the team with their student id and full name in the notebook. In this home assignment, you have to submit an .ipynb notebook and a file \"beta.npy\" as specified in task 3. Do not submit anything else than these two files!\n",
    "\n",
    "Cite ALL your sources for coding this home assignment. In case of plagiarism (copying solutions from other teams or from the internet) ALL team members will be expelled from the course without warning.\n",
    "\n",
    "If you have any general questions regarding this assignment, please ask on Moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List team members, including all student IDs here:\n",
    "1. Student 1 (123456)\n",
    "2. Student 2 (123457)\n",
    "3. (optional) Student 3 (123458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Causal Inference (1 pt)\n",
    "\n",
    "Suppose you conduct a study to evaluate the effect of a new procedure for coronary bypass surgery that is supposed to help with the postoperative healing process. Since the new procedure is more risky than the old one, it is rarely performed on patients who are over 80 years old. However, there is also hardly any data on under 80-year olds that have taken the old treatment. \n",
    "\n",
    "You can find the data from the study in \"bypass.csv\", where _stay_ is the length of the hospital stay after surgery, _age_ is the age of the patient, and _new_ is the binary indicator variable specifying whether the new surgical procedure was used. Additionally, there is a column _severity_ which quantifies the severity of preoperative diseases.\n",
    "\n",
    "Perform a regression analysis to draw a causal inference whether the new surgery method shortens the length of the postoperative hospital stay. Can you observe a significant effect? Would you generally recommend to apply the new surgery method?\n",
    "Provide a thorough explanation of your answers and the steps in your analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Naive Bayes on Continuous Data (1 pt)\n",
    "\n",
    "In lecture we have introduced the _Naive Bayes_ classifier, in which for each feature, we compute the empirical probabilities \n",
    "$ P(x_i|y) $ to form our predictions. For discrete data, we have learned in lecture that these probabilities are estimated from the raw class-conditional feature counts. For continuous features however, this approach obviously does not make sense.\n",
    "Instead, for continuous features, one usually makes the assumption that these  are normally distributed. Thus for continuous features, one usually models the class-conditional probabilities via \n",
    "$$ P(X_i = x| y = C_k) = \\frac{1}{\\sqrt{2\\pi \\sigma_{ik}^2}} \\exp\\left(-\\frac{x_i-\\mu_{ik}}{2\\sigma_{ik}^2}\\right)$$\n",
    "where $\\mu_{ik}$ and $\\sigma_{ik}$ are the mean and variance of the features $X_i$ that are classed as $c_k$.\n",
    "A Naive Bayes classifier for which all features are assumed to be continuous and normally distribited is also called _Gaussian Naive Bayes_ classifier.\n",
    "\n",
    "Implement a class that performs Naive Bayes classification on both discrete and continuous data, using the class and function signatures and specifications in the cell below, which are designed to be similar to the model classes in sklearn. \n",
    "When passing your data to the fit() function, by default your classifier should treat all columns as continuous, i.e. normally distributed as explained above. Discrete features have to be specified upon fitting, by passing a list of integers specifying the indices of the columns that are to be treated as discrete features.\n",
    "\n",
    "Note: You may use any function from the numpy library, but __NO__ function from the scikit-learn library. Further, you may assume that all input data is valid, i.e. you do not need to check whether for instance the feature matrix X has as many rows as the class vector $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__():\n",
    "        # your code here\n",
    "        \n",
    "    \n",
    "    # fit your model, nothing is returned\n",
    "    # X: two dimensional numpy array describing the feature matrix to train on\n",
    "    # y: one dimensional numpy array or list representing the class vector used in training\n",
    "    # discrete columns: optional list of indices describing the coumns in X that are to be treated as numerical.\n",
    "    def fit(X, y, discrete_columns = None):\n",
    "        # your code here\n",
    "    \n",
    "    # predict function: use the previously trained model to make a prediction\n",
    "    # -> return a vector y_hat of predicted classes.\n",
    "    # X: two dimensional numpy array describing the feature matrix to predict on\n",
    "    def predict(X):\n",
    "        # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Predicting House Prizes (3 pts)\n",
    "\n",
    "In this task you have to create a regression model to predict housing prices. We are providing you with a training dataset that you have to use to form your model, but we are going to grade your model based on the performance on a test set that is not known to you.\n",
    "\n",
    "__Grading:__ We will measure the performance of your model in terms of the MSE error on a test set that we are holding out. We will create a simple baseline model ourselves, which will be based on a little feature engineering, and a ridge regression model that is just run with default parameters from scikit-learn. To obtain 50% of the points in this task, your model should show a better performance on the test set than our baseline. The remaining 50% of the points will be awarded based on your performance against the rest of the class. The best models will get full marks, and the rest of the marks will degrade along with the testing error scores.\n",
    "\n",
    "\n",
    "__What to submit:__ In your submission, you have to provide the following things: \n",
    "1. Two functions that preprocess the input data into the format that you chose to use in your final regression model. The first function should perform the main part of the feature engineering and return an unscaled predictor matrix. Thus, its input has to be a pandas dataframe consisting of all the predictor colums in the data, and its output has to be a two-dimensional numpy array $X$. The second function should scale the preprocessed matrix. Its input is a training matrix that your scaling model is based on, and a test matrix that your scaling model is then to be applied on, to return a scaled test matrix. The exact signatures and the testing pipeline can be found below. Note that the scaling function may also perform other things than scaling, e.g. adding a constant column or adding interactions, as long as the testing pipeline below works properly. \n",
    "2. A corresponding parameter vector $\\beta$, that is saved as a numpy array into the file \"beta.npy\". It is used to compute the model predictions via $\\hat{y} = X\\beta$. Note that any other models next to regression models are not admissible.\n",
    "3. All the code that you used to optimize your final model. Submissions that show no code in that regard will not be awarded any points. Further, we encourage to report all the exploratory analysis that you did, and report some of the errors that your model achieved on some validation data. This may grant some extra points in the case that your model does not outperform our baseline on the testing data.\n",
    "\n",
    "Note that in this task, you may use any Python library that can be installed via pip. In particular, you may use libraries like statsmodel or scikit-learn. \n",
    "\n",
    "In the cells below, you can find the signatures of the preprocessing and scaling functions, the pipeline that we are going to use to make predictions, and some space where your code for exploration and optimization can go. Note that your model, i.e. both preprocessing functions and the parameter vector have to work on this pipeline. If this pipeline cell does not execute, you will not get any points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signature of preprocessing & scaling functions - you MUST use these function signatures in your final submission.\n",
    "\n",
    "def preprocess(dfX):\n",
    "    # insert your code here\n",
    "    return X #X has to be a two-dimensional numpy array\n",
    "\n",
    "# inputs are both numpy matrices\n",
    "def scale(X_train, X_test):\n",
    "    # insert your code here\n",
    "    return X_test_scaled  #X has to be a two-dimensional numpy array as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing pipeline, for illustration. Test data will have the same format as the training data. Do NOT edit this cell, \n",
    "# but feel free to copy it to test it yourself.  \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# read in data\n",
    "df_train = pd.read_csv(\"housing_train.csv\")\n",
    "df_test = pd.read_csv(\"housing_test.csv\")\n",
    "\n",
    "# split predictor dataframe from complete data\n",
    "dfX_train = df_train.iloc[:,:-1]\n",
    "dfX_test = df_test.iloc[:,:-1]\n",
    "\n",
    "# preprocess training and test data - preprocessed training data is always needed for scaling\n",
    "X_train = preprocess(dfX_train)\n",
    "X_test = preprocess(dfX_test)\n",
    "\n",
    "# finally, scale your data into a proper format. Note that for scaling the training data,\n",
    "# you should call 'X_train_scaled = scale(X_train, X_train)'\n",
    "X_test_scaled = scale(X_train,X_test)\n",
    "\n",
    "print(X_test_scaled)\n",
    "\n",
    "# load parameter vector resulting from your optimized model\n",
    "beta = np.load(\"beta.npy\")\n",
    "\n",
    "# apply your vector to predict on the test data\n",
    "y_pred = np.dot(X_test_scaled,beta)\n",
    "\n",
    "\n",
    "# get target column from test data and compute MSE\n",
    "y_test = df_test.iloc[:,-1].to_numpy()\n",
    "print(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can illustrate your process of model optimization in the cell(s) below. Feel free to add cells where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
