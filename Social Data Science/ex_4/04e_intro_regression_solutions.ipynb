{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Introduction to Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Brief Introduction to Statsmodels\n",
    "\n",
    "Next to sklearn, statsmodels is probably the most popular Python package for regression. While the focus of sklearn (will be covered later in class) rather lies machine learning applications, statsmodels (as the name suggests) has a rather statitics-oriented focus. We will briefly present the basic functionality of its regression functions by revisiting the Iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "df = pd.read_csv (\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Bivariate Prediction\n",
    "We want to fit a regession model that estimates sepal length from sepal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  sepal_width\n",
       "0    1.0          3.5\n",
       "1    1.0          3.0\n",
       "2    1.0          3.2\n",
       "3    1.0          3.1\n",
       "4    1.0          3.6\n",
       "5    1.0          3.9\n",
       "6    1.0          3.4\n",
       "7    1.0          3.4\n",
       "8    1.0          2.9\n",
       "9    1.0          3.1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify predictors X and target Y\n",
    "y = df.sepal_length\n",
    "X = df.sepal_width\n",
    "# most importantly: we have to add a constant term to estimate the intercept\n",
    "X = sm.add_constant(X)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>sepal_length</td>   <th>  R-squared:         </th> <td>   0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Nov 2019</td> <th>  Prob (F-statistic):</th>  <td> 0.183</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:37:39</td>     <th>  Log-Likelihood:    </th> <td> -183.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>      <th>  AIC:               </th> <td>   370.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   148</td>      <th>  BIC:               </th> <td>   376.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>    6.4812</td> <td>    0.481</td> <td>   13.466</td> <td> 0.000</td> <td>    5.530</td> <td>    7.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal_width</th> <td>   -0.2089</td> <td>    0.156</td> <td>   -1.339</td> <td> 0.183</td> <td>   -0.517</td> <td>    0.099</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.455</td> <th>  Durbin-Watson:     </th> <td>   0.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.108</td> <th>  Jarque-Bera (JB):  </th> <td>   4.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.356</td> <th>  Prob(JB):          </th> <td>   0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.585</td> <th>  Cond. No.          </th> <td>    24.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           sepal_length   R-squared:                       0.012\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     1.792\n",
       "Date:                Fri, 08 Nov 2019   Prob (F-statistic):              0.183\n",
       "Time:                        10:37:39   Log-Likelihood:                -183.14\n",
       "No. Observations:                 150   AIC:                             370.3\n",
       "Df Residuals:                     148   BIC:                             376.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const           6.4812      0.481     13.466      0.000       5.530       7.432\n",
       "sepal_width    -0.2089      0.156     -1.339      0.183      -0.517       0.099\n",
       "==============================================================================\n",
       "Omnibus:                        4.455   Durbin-Watson:                   0.941\n",
       "Prob(Omnibus):                  0.108   Jarque-Bera (JB):                4.252\n",
       "Skew:                           0.356   Prob(JB):                        0.119\n",
       "Kurtosis:                       2.585   Cond. No.                         24.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model: OLS = ordinary least squares\n",
    "model = sm.OLS(y,X)\n",
    "# fit model: only now te model, i.e. the parameters are computed\n",
    "results = model.fit()\n",
    "\n",
    "# print a summary, i.e. an overview on parameters and diagnostics\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const          6.481223\n",
       "sepal_width   -0.208870\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get parameters of model, i.e. beta_0 and beta_1\n",
    "params = results.params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.75017718, 5.85461233, 5.81283827, 5.8337253 , 5.72929015,\n",
       "       5.66662906, 5.77106421, 5.77106421, 5.87549936, 5.8337253 ,\n",
       "       5.70840312, 5.77106421, 5.85461233, 5.85461233, 5.64574204,\n",
       "       5.56219392, 5.66662906, 5.75017718, 5.68751609, 5.68751609,\n",
       "       5.77106421, 5.70840312, 5.72929015, 5.79195124, 5.77106421,\n",
       "       5.85461233, 5.77106421, 5.75017718, 5.77106421, 5.81283827,\n",
       "       5.8337253 , 5.77106421, 5.62485501, 5.60396798, 5.8337253 ,\n",
       "       5.81283827, 5.75017718, 5.8337253 , 5.85461233, 5.77106421,\n",
       "       5.75017718, 6.00082154, 5.81283827, 5.75017718, 5.68751609,\n",
       "       5.85461233, 5.68751609, 5.81283827, 5.70840312, 5.79195124,\n",
       "       5.81283827, 5.81283827, 5.8337253 , 6.00082154, 5.89638639,\n",
       "       5.89638639, 5.79195124, 5.97993451, 5.87549936, 5.91727342,\n",
       "       6.06348262, 5.85461233, 6.02170856, 5.87549936, 5.87549936,\n",
       "       5.8337253 , 5.85461233, 5.91727342, 6.02170856, 5.95904748,\n",
       "       5.81283827, 5.89638639, 5.95904748, 5.89638639, 5.87549936,\n",
       "       5.85461233, 5.89638639, 5.85461233, 5.87549936, 5.93816045,\n",
       "       5.97993451, 5.97993451, 5.91727342, 5.91727342, 5.85461233,\n",
       "       5.77106421, 5.8337253 , 6.00082154, 5.85461233, 5.95904748,\n",
       "       5.93816045, 5.85461233, 5.93816045, 6.00082154, 5.91727342,\n",
       "       5.85461233, 5.87549936, 5.87549936, 5.95904748, 5.89638639,\n",
       "       5.79195124, 5.91727342, 5.85461233, 5.87549936, 5.85461233,\n",
       "       5.85461233, 5.95904748, 5.87549936, 5.95904748, 5.72929015,\n",
       "       5.81283827, 5.91727342, 5.85461233, 5.95904748, 5.89638639,\n",
       "       5.81283827, 5.85461233, 5.68751609, 5.93816045, 6.02170856,\n",
       "       5.81283827, 5.89638639, 5.89638639, 5.91727342, 5.79195124,\n",
       "       5.81283827, 5.89638639, 5.85461233, 5.89638639, 5.85461233,\n",
       "       5.89638639, 5.68751609, 5.89638639, 5.89638639, 5.93816045,\n",
       "       5.85461233, 5.77106421, 5.8337253 , 5.85461233, 5.8337253 ,\n",
       "       5.8337253 , 5.8337253 , 5.91727342, 5.81283827, 5.79195124,\n",
       "       5.85461233, 5.95904748, 5.85461233, 5.77106421, 5.85461233])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can apply parameters to obtain the predictions of Y based on X\n",
    "np.dot(X,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5.750177\n",
       "1      5.854612\n",
       "2      5.812838\n",
       "3      5.833725\n",
       "4      5.729290\n",
       "5      5.666629\n",
       "6      5.771064\n",
       "7      5.771064\n",
       "8      5.875499\n",
       "9      5.833725\n",
       "10     5.708403\n",
       "11     5.771064\n",
       "12     5.854612\n",
       "13     5.854612\n",
       "14     5.645742\n",
       "15     5.562194\n",
       "16     5.666629\n",
       "17     5.750177\n",
       "18     5.687516\n",
       "19     5.687516\n",
       "20     5.771064\n",
       "21     5.708403\n",
       "22     5.729290\n",
       "23     5.791951\n",
       "24     5.771064\n",
       "25     5.854612\n",
       "26     5.771064\n",
       "27     5.750177\n",
       "28     5.771064\n",
       "29     5.812838\n",
       "         ...   \n",
       "120    5.812838\n",
       "121    5.896386\n",
       "122    5.896386\n",
       "123    5.917273\n",
       "124    5.791951\n",
       "125    5.812838\n",
       "126    5.896386\n",
       "127    5.854612\n",
       "128    5.896386\n",
       "129    5.854612\n",
       "130    5.896386\n",
       "131    5.687516\n",
       "132    5.896386\n",
       "133    5.896386\n",
       "134    5.938160\n",
       "135    5.854612\n",
       "136    5.771064\n",
       "137    5.833725\n",
       "138    5.854612\n",
       "139    5.833725\n",
       "140    5.833725\n",
       "141    5.833725\n",
       "142    5.917273\n",
       "143    5.812838\n",
       "144    5.791951\n",
       "145    5.854612\n",
       "146    5.959047\n",
       "147    5.854612\n",
       "148    5.771064\n",
       "149    5.854612\n",
       "Length: 150, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unsurprisingly, statsmodels also provides a direct prediction function:\n",
    "results.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Multivariate Regression\n",
    "Now we want to include all other numerical columns from the data to fit to estimate sepal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>sepal_length</td>   <th>  R-squared:         </th> <td>   0.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.856</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   297.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>6.28e-62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:37:59</td>     <th>  Log-Likelihood:    </th> <td> -37.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>      <th>  AIC:               </th> <td>   82.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   146</td>      <th>  BIC:               </th> <td>   94.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>    1.8451</td> <td>    0.250</td> <td>    7.368</td> <td> 0.000</td> <td>    1.350</td> <td>    2.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal_width</th>  <td>    0.6549</td> <td>    0.067</td> <td>    9.823</td> <td> 0.000</td> <td>    0.523</td> <td>    0.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>petal_width</th>  <td>   -0.5626</td> <td>    0.127</td> <td>   -4.426</td> <td> 0.000</td> <td>   -0.814</td> <td>   -0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>petal_length</th> <td>    0.7111</td> <td>    0.057</td> <td>   12.560</td> <td> 0.000</td> <td>    0.599</td> <td>    0.823</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.265</td> <th>  Durbin-Watson:     </th> <td>   2.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.876</td> <th>  Jarque-Bera (JB):  </th> <td>   0.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.003</td> <th>  Prob(JB):          </th> <td>   0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.737</td> <th>  Cond. No.          </th> <td>    54.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           sepal_length   R-squared:                       0.859\n",
       "Model:                            OLS   Adj. R-squared:                  0.856\n",
       "Method:                 Least Squares   F-statistic:                     297.0\n",
       "Date:                Fri, 08 Nov 2019   Prob (F-statistic):           6.28e-62\n",
       "Time:                        10:37:59   Log-Likelihood:                -37.000\n",
       "No. Observations:                 150   AIC:                             82.00\n",
       "Df Residuals:                     146   BIC:                             94.04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept        1.8451      0.250      7.368      0.000       1.350       2.340\n",
       "sepal_width      0.6549      0.067      9.823      0.000       0.523       0.787\n",
       "petal_width     -0.5626      0.127     -4.426      0.000      -0.814      -0.311\n",
       "petal_length     0.7111      0.057     12.560      0.000       0.599       0.823\n",
       "==============================================================================\n",
       "Omnibus:                        0.265   Durbin-Watson:                   2.053\n",
       "Prob(Omnibus):                  0.876   Jarque-Bera (JB):                0.432\n",
       "Skew:                           0.003   Prob(JB):                        0.806\n",
       "Kurtosis:                       2.737   Cond. No.                         54.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statsmodels also provides a formula syntax, which requires an additional import\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# formula syntax: dependent variable ~ predictor1 + predictor2 +.....\n",
    "# note that intercept is fit automatically\n",
    "model = ols(\"sepal_length ~ sepal_width + petal_width + petal_length\", data=df)\n",
    "\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>sepal_length</td>   <th>  R-squared:         </th> <td>   0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   186.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>4.20e-61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:38:03</td>     <th>  Log-Likelihood:    </th> <td> -33.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>      <th>  AIC:               </th> <td>   78.06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   144</td>      <th>  BIC:               </th> <td>   96.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>    2.0983</td> <td>    0.476</td> <td>    4.408</td> <td> 0.000</td> <td>    1.157</td> <td>    3.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal_width:petal_width</th> <td>   -0.1255</td> <td>    0.100</td> <td>   -1.250</td> <td> 0.213</td> <td>   -0.324</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.square(petal_length)</th> <td>    0.0333</td> <td>    0.013</td> <td>    2.571</td> <td> 0.011</td> <td>    0.008</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal_width</th>             <td>    0.6790</td> <td>    0.123</td> <td>    5.541</td> <td> 0.000</td> <td>    0.437</td> <td>    0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>petal_width</th>             <td>   -0.1154</td> <td>    0.344</td> <td>   -0.335</td> <td> 0.738</td> <td>   -0.796</td> <td>    0.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>petal_length</th>            <td>    0.4470</td> <td>    0.117</td> <td>    3.821</td> <td> 0.000</td> <td>    0.216</td> <td>    0.678</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.119</td> <th>  Durbin-Watson:     </th> <td>   1.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.942</td> <th>  Jarque-Bera (JB):  </th> <td>   0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.021</td> <th>  Prob(JB):          </th> <td>   0.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.794</td> <th>  Cond. No.          </th> <td>    483.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           sepal_length   R-squared:                       0.866\n",
       "Model:                            OLS   Adj. R-squared:                  0.862\n",
       "Method:                 Least Squares   F-statistic:                     186.9\n",
       "Date:                Fri, 08 Nov 2019   Prob (F-statistic):           4.20e-61\n",
       "Time:                        10:38:03   Log-Likelihood:                -33.031\n",
       "No. Observations:                 150   AIC:                             78.06\n",
       "Df Residuals:                     144   BIC:                             96.13\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                   2.0983      0.476      4.408      0.000       1.157       3.039\n",
       "sepal_width:petal_width    -0.1255      0.100     -1.250      0.213      -0.324       0.073\n",
       "np.square(petal_length)     0.0333      0.013      2.571      0.011       0.008       0.059\n",
       "sepal_width                 0.6790      0.123      5.541      0.000       0.437       0.921\n",
       "petal_width                -0.1154      0.344     -0.335      0.738      -0.796       0.565\n",
       "petal_length                0.4470      0.117      3.821      0.000       0.216       0.678\n",
       "==============================================================================\n",
       "Omnibus:                        0.119   Durbin-Watson:                   1.996\n",
       "Prob(Omnibus):                  0.942   Jarque-Bera (JB):                0.276\n",
       "Skew:                           0.021   Prob(JB):                        0.871\n",
       "Kurtosis:                       2.794   Cond. No.                         483.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formula syntax: dependent variable ~ predictor1 + predictor2 +.....\n",
    "# note that intercept is fit automatically\n",
    "\n",
    "# add interaction and squared term\n",
    "model = ols(\"sepal_length ~ sepal_width:petal_width + np.square(petal_length) + sepal_width + petal_width + petal_length\", data=df)\n",
    "\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Fitting an artificial data set\n",
    "\n",
    "We want to implement OLS regression and test it on artificial data. Thus, in this task you may not yet use the statsmodels functions (except for checking results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Creating artificial data\n",
    "Create an artificial dataset which consists of:\n",
    "* a vector $x$ consisting of 100 (float) values between 0 and 1\n",
    "* a vector $y = 10x +\\varepsilon$, in which for each element, the error $\\varepsilon_i$ is drawn from the standard normal distribution.\n",
    "Create a scatterplot of x against y!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw 1000 values from unitform distribution\n",
    "X = np.random.uniform(0,1,100)\n",
    "\n",
    "# create vector of 100 error values drawn from standard normal distribution\n",
    "eps = np.random.normal(0,1,100)\n",
    "\n",
    "# target vector\n",
    "y = 10*X + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#plot values, underlying model should be visible\n",
    "plt.scatter(X, y, color = \"blue\", s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Implementing OLS regression\n",
    "Write a function that takes as input a numpy vector of target values $y$, and a matrix of predictors $X$, and returns the parameter vector $\\beta$ resulting from OLS regression. Apply this function to fit a model on your artificial data, compute the predictions, and add the resulting regression line to the plot from a). Remember to add a constant term!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.21193775 10.29099176]\n"
     ]
    }
   ],
   "source": [
    "def lm_fit(y,X):\n",
    "    A = np.linalg.inv(np.dot(X.T,X))\n",
    "    C = np.dot(X.T,y)\n",
    "    return np.dot(A,C)\n",
    "\n",
    "# non-statsmodels way to add constant column\n",
    "Xc = np.vstack([np.ones(len(X)),X]).T\n",
    "beta = lm_fit(y,Xc)\n",
    "print(beta) # betas are slightly off to what would be expected, this is due to variance in errors being relatively big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(X,y, s = 0.5)\n",
    "\n",
    "# plot regression line\n",
    "xl = [0,1]\n",
    "yl = [beta[0], beta[0] + beta[1]]\n",
    "plt.plot(xl,yl, color = \"red\")\n",
    "\n",
    "# plot observations\n",
    "plt.scatter(X, y, color = \"blue\", s=1)\n",
    "plt.xlim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Diagnostics 1: The Bootstrap\n",
    "\n",
    "Based on your regression function, write a function that again takes as input a predictor matrix $X$ and a target column $y$, plus a integer $N$, and bootstraps the data $N$ times to compute the 95% confidence interval for each parameter. Specifically, return one parameter vector for the bottom beta values, and one parameter vector for the top values. \n",
    "Apply this function to estimate the confidence intervals on our artificial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.21193775, 10.29099176]), array([-0.5029775 ,  9.63416212]), array([ 0.09969174, 10.93911446]))\n"
     ]
    }
   ],
   "source": [
    "def lm_ci(y, X, N):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # parameter matrix, each row is the parameter vector of one model\n",
    "    beta_all = np.zeros((N,m))\n",
    "    n = len(y)\n",
    "    \n",
    "    #bootstrap: fit N models and save their parameters\n",
    "    for i in range(N):\n",
    "        ind = np.random.choice(np.arange(n),n)\n",
    "        Xs = X[ind]\n",
    "        ys = y[ind]\n",
    "        beta_all[i] = lm_fit(ys,Xs)\n",
    "        \n",
    "    # most important fo CIs: sort al columns    \n",
    "    for j in range(m):\n",
    "        beta_all[:,j] = np.sort(beta_all[:,j])\n",
    "    \n",
    "    # get confidence intervals\n",
    "    ci_low, ci_high = int(0.025*N-1), int(0.975*N-1) \n",
    "    \n",
    "    # fit actual model\n",
    "    beta = lm_fit(y,X)\n",
    "        \n",
    "    return (beta, beta_all[ci_low], beta_all[ci_high])\n",
    "\n",
    "ci = lm_ci(y, Xc, 10000)\n",
    "print(ci) # \"true\" beta = [0,10] in confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Diagnostics 2: The $R^2$ score.\n",
    "\n",
    "Write a function that takes as input a ground truth vector y, its prediction y_hat, and computes the $R^2$ value of that prediction! Does your model explain most of the variance in the artificial data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9076344885598039\n"
     ]
    }
   ],
   "source": [
    "def R_sq(y,y_hat):\n",
    "    rss = np.sum((y-y_hat)**2)\n",
    "    mu = np.mean(y)\n",
    "    tss = np.sum((y-mu)**2)\n",
    "    return 1 - rss/tss\n",
    "\n",
    "print(R_sq(y, Xc.dot(beta))) # most variance explained, so even of the variance was relatively large, we could model it very well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Predicting Student Performance\n",
    "\n",
    "We revisit the student performance dataset from last week's exercise and aim to estimate the exam performance in math. In this task you may use statsmodels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Data Preprocessing\n",
    "\n",
    "Load the student performance data into a dataframe. Since we want to estimate students performance in math, separate this column from the dataframe. On the remaining columns, transform, i.e. dummy-code all categorical columns as explained in lecture. Further, check for collinearities. If a pair of highly correlated columns (i.e. pearson correlation > 0.9) is given, remove one of these columns from the predictors. Remember to add a constant term afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>race/ethnicity_group B</th>\n",
       "      <th>race/ethnicity_group C</th>\n",
       "      <th>race/ethnicity_group D</th>\n",
       "      <th>race/ethnicity_group E</th>\n",
       "      <th>parental level of education_bachelor's degree</th>\n",
       "      <th>parental level of education_high school</th>\n",
       "      <th>parental level of education_master's degree</th>\n",
       "      <th>parental level of education_some college</th>\n",
       "      <th>parental level of education_some high school</th>\n",
       "      <th>lunch_standard</th>\n",
       "      <th>test preparation course_none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   math score  reading score  writing score  gender_male  \\\n",
       "0          72             72             74            0   \n",
       "1          69             90             88            0   \n",
       "2          90             95             93            0   \n",
       "3          47             57             44            1   \n",
       "4          76             78             75            1   \n",
       "\n",
       "   race/ethnicity_group B  race/ethnicity_group C  race/ethnicity_group D  \\\n",
       "0                       1                       0                       0   \n",
       "1                       0                       1                       0   \n",
       "2                       1                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       1                       0   \n",
       "\n",
       "   race/ethnicity_group E  parental level of education_bachelor's degree  \\\n",
       "0                       0                                              1   \n",
       "1                       0                                              0   \n",
       "2                       0                                              0   \n",
       "3                       0                                              0   \n",
       "4                       0                                              0   \n",
       "\n",
       "   parental level of education_high school  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   parental level of education_master's degree  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            1   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   parental level of education_some college  \\\n",
       "0                                         0   \n",
       "1                                         1   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         1   \n",
       "\n",
       "   parental level of education_some high school  lunch_standard  \\\n",
       "0                                             0               1   \n",
       "1                                             0               1   \n",
       "2                                             0               1   \n",
       "3                                             0               0   \n",
       "4                                             0               1   \n",
       "\n",
       "   test preparation course_none  \n",
       "0                             1  \n",
       "1                             0  \n",
       "2                             1  \n",
       "3                             1  \n",
       "4                             1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"StudentsPerformance.csv\")\n",
    "\n",
    "# transform categorical values to 0-1 representations, drop first category to avoid collinearities\n",
    "df = pd.get_dummies(df, drop_first = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  0,  1,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13],\n",
      "      dtype=int64), array([ 0,  1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13],\n",
      "      dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(df.iloc[:,1:].corr() > 0.8)) # writing and reading are highly correlated!\n",
    "\n",
    "# omit column 0 (target variable), and column 1 (reading score) in X\n",
    "X = sm.add_constant(df.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Learning a simple regression model\n",
    "\n",
    "Apply statsmodels to estimate the exam performance in math from all other columns, without any column interactions. Remember to use a constant term, and properly transform categorical variables. Which significant effects do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>math score</td>    <th>  R-squared:         </th> <td>   0.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   515.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Nov 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:48:40</td>     <th>  Log-Likelihood:    </th> <td> -3110.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   6249.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   986</td>      <th>  BIC:               </th> <td>   6317.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                        <td></td>                           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                                         <td>  -11.4401</td> <td>    1.268</td> <td>   -9.019</td> <td> 0.000</td> <td>  -13.929</td> <td>   -8.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>writing score</th>                                 <td>    0.9605</td> <td>    0.014</td> <td>   68.886</td> <td> 0.000</td> <td>    0.933</td> <td>    0.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_male</th>                                   <td>   13.7321</td> <td>    0.371</td> <td>   37.059</td> <td> 0.000</td> <td>   13.005</td> <td>   14.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race/ethnicity_group B</th>                        <td>    0.8689</td> <td>    0.706</td> <td>    1.231</td> <td> 0.218</td> <td>   -0.516</td> <td>    2.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race/ethnicity_group C</th>                        <td>    0.1528</td> <td>    0.661</td> <td>    0.231</td> <td> 0.817</td> <td>   -1.145</td> <td>    1.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race/ethnicity_group D</th>                        <td>   -0.3552</td> <td>    0.679</td> <td>   -0.523</td> <td> 0.601</td> <td>   -1.688</td> <td>    0.977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race/ethnicity_group E</th>                        <td>    5.2006</td> <td>    0.751</td> <td>    6.924</td> <td> 0.000</td> <td>    3.727</td> <td>    6.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parental level of education_bachelor's degree</th> <td>   -1.3810</td> <td>    0.625</td> <td>   -2.209</td> <td> 0.027</td> <td>   -2.608</td> <td>   -0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parental level of education_high school</th>       <td>    0.7817</td> <td>    0.544</td> <td>    1.436</td> <td> 0.151</td> <td>   -0.287</td> <td>    1.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parental level of education_master's degree</th>   <td>   -2.0899</td> <td>    0.808</td> <td>   -2.588</td> <td> 0.010</td> <td>   -3.675</td> <td>   -0.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parental level of education_some college</th>      <td>    0.3014</td> <td>    0.518</td> <td>    0.582</td> <td> 0.561</td> <td>   -0.714</td> <td>    1.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parental level of education_some high school</th>  <td>    0.8631</td> <td>    0.558</td> <td>    1.546</td> <td> 0.122</td> <td>   -0.232</td> <td>    1.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lunch_standard</th>                                <td>    2.9984</td> <td>    0.380</td> <td>    7.895</td> <td> 0.000</td> <td>    2.253</td> <td>    3.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test preparation course_none</th>                  <td>    4.1663</td> <td>    0.390</td> <td>   10.697</td> <td> 0.000</td> <td>    3.402</td> <td>    4.931</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.054</td> <th>  Durbin-Watson:     </th> <td>   1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.590</td> <th>  Jarque-Bera (JB):  </th> <td>   1.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.039</td> <th>  Prob(JB):          </th> <td>   0.574</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.857</td> <th>  Cond. No.          </th> <td>    608.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             math score   R-squared:                       0.872\n",
       "Model:                            OLS   Adj. R-squared:                  0.870\n",
       "Method:                 Least Squares   F-statistic:                     515.7\n",
       "Date:                Fri, 08 Nov 2019   Prob (F-statistic):               0.00\n",
       "Time:                        10:48:40   Log-Likelihood:                -3110.3\n",
       "No. Observations:                1000   AIC:                             6249.\n",
       "Df Residuals:                     986   BIC:                             6317.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================================\n",
       "                                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------------\n",
       "const                                           -11.4401      1.268     -9.019      0.000     -13.929      -8.951\n",
       "writing score                                     0.9605      0.014     68.886      0.000       0.933       0.988\n",
       "gender_male                                      13.7321      0.371     37.059      0.000      13.005      14.459\n",
       "race/ethnicity_group B                            0.8689      0.706      1.231      0.218      -0.516       2.254\n",
       "race/ethnicity_group C                            0.1528      0.661      0.231      0.817      -1.145       1.451\n",
       "race/ethnicity_group D                           -0.3552      0.679     -0.523      0.601      -1.688       0.977\n",
       "race/ethnicity_group E                            5.2006      0.751      6.924      0.000       3.727       6.674\n",
       "parental level of education_bachelor's degree    -1.3810      0.625     -2.209      0.027      -2.608      -0.154\n",
       "parental level of education_high school           0.7817      0.544      1.436      0.151      -0.287       1.850\n",
       "parental level of education_master's degree      -2.0899      0.808     -2.588      0.010      -3.675      -0.505\n",
       "parental level of education_some college          0.3014      0.518      0.582      0.561      -0.714       1.317\n",
       "parental level of education_some high school      0.8631      0.558      1.546      0.122      -0.232       1.958\n",
       "lunch_standard                                    2.9984      0.380      7.895      0.000       2.253       3.744\n",
       "test preparation course_none                      4.1663      0.390     10.697      0.000       3.402       4.931\n",
       "==============================================================================\n",
       "Omnibus:                        1.054   Durbin-Watson:                   1.973\n",
       "Prob(Omnibus):                  0.590   Jarque-Bera (JB):                1.112\n",
       "Skew:                          -0.039   Prob(JB):                        0.574\n",
       "Kurtosis:                       2.857   Cond. No.                         608.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,0]\n",
    "\n",
    "# initialize and fit OLS model\n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "\n",
    "# print summary, i.e. an overview on parameters and diagnostics\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Adding interactions\n",
    "Apply statsmodels to fit a regression model that in addition to the previous model further considers an interaction term between the test preparation curse and each of the continuous columns that are left from the preprocessing. Thus, first add these columns to your predictor matrix, and then compute the corresponding model.\n",
    "Does this interaction yield an improvement or rather cause problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>math score</td>    <th>  R-squared:         </th> <td>   0.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   480.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Nov 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:49:10</td>     <th>  Log-Likelihood:    </th> <td> -3108.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   6247.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   985</td>      <th>  BIC:               </th> <td>   6321.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                        <td></td>                           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                                         <td>  -13.9232</td> <td>    1.878</td> <td>   -7.413</td> <td> 0.000</td> <td>  -17.609</td> <td>  -10.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>writing score</th>                                 <td>    0.9931</td> <td>    0.023</td> <td>   43.279</td> <td> 0.000</td> <td>    0.948</td> <td>    1.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_male</th>                                   <td>   13.7542</td> <td>    0.370</td> <td>   37.139</td> <td> 0.000</td> <td>   13.027</td> <td>   14.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race/ethnicity_group B</th>                        <td>    0.8986</td> <td>    0.705</td> <td>    1.275</td> <td> 0.203</td> <td>   -0.485</td> <td>    2.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race/ethnicity_group C</th>                        <td>    0.1724</td> <td>    0.661</td> <td>    0.261</td> <td> 0.794</td> <td>   -1.124</td> <td>    1.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race/ethnicity_group D</th>                        <td>   -0.3309</td> <td>    0.678</td> <td>   -0.488</td> <td> 0.626</td> <td>   -1.662</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race/ethnicity_group E</th>                        <td>    5.2320</td> <td>    0.750</td> <td>    6.972</td> <td> 0.000</td> <td>    3.759</td> <td>    6.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parental level of education_bachelor's degree</th> <td>   -1.3702</td> <td>    0.625</td> <td>   -2.194</td> <td> 0.028</td> <td>   -2.596</td> <td>   -0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parental level of education_high school</th>       <td>    0.8152</td> <td>    0.544</td> <td>    1.498</td> <td> 0.134</td> <td>   -0.252</td> <td>    1.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parental level of education_master's degree</th>   <td>   -2.0513</td> <td>    0.807</td> <td>   -2.542</td> <td> 0.011</td> <td>   -3.635</td> <td>   -0.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parental level of education_some college</th>      <td>    0.2990</td> <td>    0.517</td> <td>    0.578</td> <td> 0.563</td> <td>   -0.716</td> <td>    1.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parental level of education_some high school</th>  <td>    0.9089</td> <td>    0.558</td> <td>    1.629</td> <td> 0.104</td> <td>   -0.186</td> <td>    2.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lunch_standard</th>                                <td>    3.0000</td> <td>    0.379</td> <td>    7.908</td> <td> 0.000</td> <td>    2.256</td> <td>    3.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test preparation course_none</th>                  <td>    7.4964</td> <td>    1.900</td> <td>    3.946</td> <td> 0.000</td> <td>    3.768</td> <td>   11.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>inter</th>                                         <td>   -0.0466</td> <td>    0.026</td> <td>   -1.791</td> <td> 0.074</td> <td>   -0.098</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.673</td> <th>  Durbin-Watson:     </th> <td>   1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.714</td> <th>  Jarque-Bera (JB):  </th> <td>   0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.040</td> <th>  Prob(JB):          </th> <td>   0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.891</td> <th>  Cond. No.          </th> <td>1.22e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.22e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             math score   R-squared:                       0.872\n",
       "Model:                            OLS   Adj. R-squared:                  0.870\n",
       "Method:                 Least Squares   F-statistic:                     480.2\n",
       "Date:                Fri, 08 Nov 2019   Prob (F-statistic):               0.00\n",
       "Time:                        10:49:10   Log-Likelihood:                -3108.6\n",
       "No. Observations:                1000   AIC:                             6247.\n",
       "Df Residuals:                     985   BIC:                             6321.\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================================\n",
       "                                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------------\n",
       "const                                           -13.9232      1.878     -7.413      0.000     -17.609     -10.237\n",
       "writing score                                     0.9931      0.023     43.279      0.000       0.948       1.038\n",
       "gender_male                                      13.7542      0.370     37.139      0.000      13.027      14.481\n",
       "race/ethnicity_group B                            0.8986      0.705      1.275      0.203      -0.485       2.282\n",
       "race/ethnicity_group C                            0.1724      0.661      0.261      0.794      -1.124       1.469\n",
       "race/ethnicity_group D                           -0.3309      0.678     -0.488      0.626      -1.662       1.000\n",
       "race/ethnicity_group E                            5.2320      0.750      6.972      0.000       3.759       6.705\n",
       "parental level of education_bachelor's degree    -1.3702      0.625     -2.194      0.028      -2.596      -0.145\n",
       "parental level of education_high school           0.8152      0.544      1.498      0.134      -0.252       1.883\n",
       "parental level of education_master's degree      -2.0513      0.807     -2.542      0.011      -3.635      -0.468\n",
       "parental level of education_some college          0.2990      0.517      0.578      0.563      -0.716       1.314\n",
       "parental level of education_some high school      0.9089      0.558      1.629      0.104      -0.186       2.004\n",
       "lunch_standard                                    3.0000      0.379      7.908      0.000       2.256       3.744\n",
       "test preparation course_none                      7.4964      1.900      3.946      0.000       3.768      11.225\n",
       "inter                                            -0.0466      0.026     -1.791      0.074      -0.098       0.004\n",
       "==============================================================================\n",
       "Omnibus:                        0.673   Durbin-Watson:                   1.972\n",
       "Prob(Omnibus):                  0.714   Jarque-Bera (JB):                0.759\n",
       "Skew:                          -0.040   Prob(JB):                        0.684\n",
       "Kurtosis:                       2.891   Cond. No.                     1.22e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.22e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"inter\"] = X.loc[:,\"writing score\"]*X.loc[:,\"test preparation course_none\"]\n",
    "\n",
    "# initialize model: OLS = ordinary least squares\n",
    "model = sm.OLS(y,X)\n",
    "# fit model: only now te model, i.e. the parameters are computed\n",
    "results = model.fit()\n",
    "\n",
    "# print a summary, i.e. an overview on parameters and diagnostics\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ The interaction term does not seem to improve the R but rather introduced multicollinaerities to the covariance matrix. Thus, in this case it did not helo to introduce this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Optimizing adjusted R^2\n",
    "\n",
    "Implement a forward selection routine that takes as input a matrix $X$ of predictors, the index of the constant column in $X$, and a target vector $y$, and returns a submatrix of predictors that produces the optimal adjusted R^2 value, plus a vector of the corresponding column indices, the corresponding parameter vector beta, and the optimal adjusted R value.\n",
    "Apply this function on the predictor matrix from part c). Which predictors are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-2.220446049250313e-16,\n",
       "  0.6438777752230129,\n",
       "  0.8285477547724039,\n",
       "  0.8442310072054959,\n",
       "  0.8578839327813405,\n",
       "  0.8672915787180262,\n",
       "  0.8684427625961662,\n",
       "  0.8697387380261092,\n",
       "  0.8701863779843868,\n",
       "  0.8704333028827219,\n",
       "  0.8704655076273414,\n",
       "  0.8705917494323717,\n",
       "  0.8706020682559741],\n",
       " array([-13.63100513,   0.99304593,  13.74610528,   7.4932352 ,\n",
       "          5.09424455,   3.00269051,  -2.20174189,  -1.52439737,\n",
       "          0.762572  ,  -0.04652333,   0.74730355,   0.66196011,\n",
       "         -0.4539947 ]),\n",
       " [0, 1, 2, 13, 6, 12, 9, 7, 3, 14, 11, 8, 5],\n",
       " array([[ 1., 74.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1., 88.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1., 93.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 1., 65.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 1., 77.,  0., ...,  0.,  0.,  1.],\n",
       "        [ 1., 86.,  0., ...,  0.,  0.,  1.]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adj_r2(y,y_hat,n,p):\n",
    "    return 1 - (1-R_sq(y,y_hat))*(n-1)/(n-p-1)\n",
    "\n",
    "def forward_select(y,X, ic = 0):\n",
    "    n = len(y)\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # list of predictors that are taken into model\n",
    "    predictors = []\n",
    "    # list of adj R scores that correspond to model with current chpice of predictors\n",
    "    r2_list = []\n",
    "    \n",
    "    # vector of candidate columns that are not (yet) chosen as predictors\n",
    "    candidates = np.arange(m)\n",
    "    \n",
    "    # ic = index of constant column, ic < 0 means no constant column exists\n",
    "    if ic < 0:\n",
    "        p = 0\n",
    "        r2_max = sm.OLS(y, X[:,0]).fit().rsquared_adj\n",
    "        r2_list.append(r2_max)\n",
    "    else:\n",
    "        # if available, constant column is always added to predictors\n",
    "        p=1\n",
    "        predictors.append(ic)\n",
    "        candidates = np.setdiff1d(np.arange(m), np.array([ic])) # remove ic from candidate columns\n",
    "        r2_max = sm.OLS(y, X[:,predictors]).fit().rsquared_adj\n",
    "        r2_list.append(r2_max)\n",
    "    \n",
    "    # actual forward selection starts here\n",
    "    update = True\n",
    "    while p < m:\n",
    "        \n",
    "        update = False\n",
    "        # find best new predictor\n",
    "        for ind in candidates:\n",
    "            p_tmp = predictors + [ind]\n",
    "            score = sm.OLS(y, X[:,p_tmp]).fit().rsquared_adj # get adj R directly from sm.OLS model\n",
    "            if score > r2_max:\n",
    "                r2_max = score\n",
    "                ind_max = ind\n",
    "                update = True\n",
    "        \n",
    "        # break iteration if no improvement on adj R was given\n",
    "        if not update:\n",
    "            break # there's surely other elegant ways to design the forwrd slection loop\n",
    "        \n",
    "        # update predictors/candidates\n",
    "        predictors.append(ind_max)\n",
    "        r2_list.append(r2_max)\n",
    "        candidates = np.setdiff1d(candidates, np.array([ind_max]))\n",
    "        \n",
    "        p+=1\n",
    "    \n",
    "    # (re)compute final model\n",
    "    res = sm.OLS(y, X[:,predictors]).fit()\n",
    "    \n",
    "    return r2_list, res.params, predictors, X[:,predictors]\n",
    "    \n",
    "# fit model: only now te model, i.e. the parameters are computed\n",
    "forward_select(np.array(y),np.array(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ Ultimately, all predictors are kept, but the improvements in adjusted R are rather marginal in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Checking residuals\n",
    "Create a residual plot of your final model and give an interpretation of what you observe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x298cf86cc88>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "residuals = results.predict(X) - y \n",
    "residuals\n",
    "plt.scatter(y,residuals)\n",
    "plt.axhline(y=0, color = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ The model appears to predict conservatively, i.e., it tends to overestimate where scores are low, and underestimate where the scores are high. This is also due to the natural boundaries in the plot, and thus the least-squares estimation accounts for the little skew in the residual plot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
